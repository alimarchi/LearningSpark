{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181c4770",
   "metadata": {},
   "source": [
    "Authors/ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06898a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following example, we want to aggregate all the ages for each name, group byname, \n",
    "# and then average the ages, using RDD\n",
    "\n",
    "dataRDD = sc.parallelize([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665af9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agesRDD = (dataRDD\n",
    "    .map(lambda x: (x[0], (x[1], 1)))\n",
    "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "    .map(lambda x: (x[0], x[1][0]/x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4f293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "| Denny|    31.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The same query using DataFrame\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Creo un DataFrame usando SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"AuthorsAges\")\n",
    "        .getOrCreate())\n",
    "\n",
    "# Creo el DataFrame\n",
    "\n",
    "data_df = spark.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), \n",
    "                                 (\"Brooke\", 25)], [\"name\", \"age\"])\n",
    "\n",
    "avg_df = data_df.groupBy(\"name\").agg(avg(\"age\"))\n",
    "avg_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7d686",
   "metadata": {},
   "source": [
    "Blog example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e916c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([StructField(\"author\", StringType(), False),\n",
    " StructField(\"title\", StringType(), False),\n",
    " StructField(\"pages\", IntegerType(), False)])\n",
    "\n",
    "# Usando DDL (Data Definition Language)\n",
    "\n",
    "schema = \"author STRING, title STRING, pages INT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19594d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Defino el schema para los datos usando DDL\n",
    "\n",
    "schema = \"`Id` INT, `First` STRING, `Last` STRING, `Url` STRING, `Published` STRING, `Hits` INT, `Campaigns` ARRAY<STRING>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f97b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\",\n",
    "\"LinkedIn\"]],\n",
    " [2, \"Brooke\",\"Wenig\", \"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\",\n",
    "\"LinkedIn\"]],\n",
    " [3, \"Denny\", \"Lee\", \"https://tinyurl.3\", \"6/7/2019\", 7659, [\"web\",\n",
    "\"twitter\", \"FB\", \"LinkedIn\"]],\n",
    " [4, \"Tathagata\", \"Das\", \"https://tinyurl.4\", \"5/12/2018\", 10568,\n",
    "[\"twitter\", \"FB\"]],\n",
    " [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\",\n",
    "\"twitter\", \"FB\", \"LinkedIn\"]],\n",
    " [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568,\n",
    "[\"twitter\", \"LinkedIn\"]]\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29274538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    " .builder\n",
    " .appName(\"Example-3_6\")\n",
    " .getOrCreate())\n",
    "\n",
    "# Creo un DataFrame usando el schema que he definido arriba\n",
    "\n",
    "blogs_df = spark.createDataFrame(data, schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ce28fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "107d7e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el schema que ha usado Spark para procesar el DataFrame\n",
    "\n",
    "print(blogs_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d906bfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reynold'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "blog_row = Row(6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", 255568, \"3/2/2015\",\n",
    " [\"twitter\", \"LinkedIn\"])\n",
    "\n",
    "blog_row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d70d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|      Authors|State|\n",
      "+-------------+-----+\n",
      "|Matei Zaharia|   CA|\n",
      "|  Reynold Xin|   CA|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Puedo usar un objeto row para crear un DataFrame\n",
    "\n",
    "rows = [Row(\"Matei Zaharia\", \"CA\"), Row(\"Reynold Xin\", \"CA\")]\n",
    "authors_df = spark.createDataFrame(rows, [\"Authors\", \"State\"])\n",
    "authors_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5450e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Defino schema de manera programatica \n",
    "\n",
    "fire_schema = StructType([StructField('CallNumber', IntegerType(), True),\n",
    "     StructField('UnitID', StringType(), True),\n",
    "     StructField('IncidentNumber', IntegerType(), True),\n",
    "     StructField('CallType', StringType(), True), \n",
    "     StructField('CallDate', StringType(), True), \n",
    "     StructField('WatchDate', StringType(), True),\n",
    "     StructField('CallFinalDisposition', StringType(), True),\n",
    "     StructField('AvailableDtTm', StringType(), True),\n",
    "     StructField('Address', StringType(), True), \n",
    "     StructField('City', StringType(), True), \n",
    "     StructField('Zipcode', IntegerType(), True), \n",
    "     StructField('Battalion', StringType(), True), \n",
    "     StructField('StationArea', StringType(), True), \n",
    "     StructField('Box', StringType(), True), \n",
    "     StructField('OriginalPriority', StringType(), True), \n",
    "     StructField('Priority', StringType(), True), \n",
    "     StructField('FinalPriority', IntegerType(), True), \n",
    "     StructField('ALSUnit', BooleanType(), True), \n",
    "     StructField('CallTypeGroup', StringType(), True),\n",
    "     StructField('NumAlarms', IntegerType(), True),\n",
    "     StructField('UnitType', StringType(), True),\n",
    "     StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n",
    "     StructField('FirePreventionDistrict', StringType(), True),\n",
    "     StructField('SupervisorDistrict', StringType(), True),\n",
    "     StructField('Neighborhood', StringType(), True),\n",
    "     StructField('Location', StringType(), True),\n",
    "     StructField('RowID', StringType(), True),\n",
    "     StructField('Delay', FloatType(), True)])\n",
    "\n",
    "# Uso el DataFrameReader para leer el fichero csv\n",
    "\n",
    "sf_fire_file = \"C:/Users/alice.marchi/Downloads/LearningSparkV2-master/chapter3/data/sf-fire-calls.csv\"\n",
    "fire_df = spark.read.csv(sf_fire_file, header=True, schema=fire_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ba2796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Projections and filters\n",
    "\n",
    "few_fire_df = (fire_df\n",
    " .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    " .where(col(\"CallType\") != \"Medical Incident\"))\n",
    "few_fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd4a76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Devuleve el número de diferentes tipos de llamadas\n",
    "\n",
    "(fire_df\n",
    " .select(\"CallType\")\n",
    " .where(col(\"CallType\").isNotNull())\n",
    " .agg(countDistinct(\"CallType\").alias(\"DistinctCallTypes\"))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88e82fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|CallType                           |\n",
      "+-----------------------------------+\n",
      "|Elevator / Escalator Rescue        |\n",
      "|Marine Fire                        |\n",
      "|Aircraft Emergency                 |\n",
      "|Confined Space / Structure Collapse|\n",
      "|Administrative                     |\n",
      "|Alarms                             |\n",
      "|Odor (Strange / Unknown)           |\n",
      "|Citizen Assist / Service Call      |\n",
      "|HazMat                             |\n",
      "|Watercraft in Distress             |\n",
      "+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtro todos los tipos de CallType, que no son null\n",
    "(fire_df\n",
    " .select(\"CallType\")\n",
    " .where(col(\"CallType\").isNotNull())\n",
    " .distinct()\n",
    " .show(10, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8de1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_fire_df = fire_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "(new_fire_df\n",
    " .select(\"ResponseDelayedinMins\")\n",
    " .where(col(\"ResponseDelayedinMins\") > 5)\n",
    " .show(5, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54aa3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso la función to_timestamp() para pasar del formato string al formato data\n",
    "\n",
    "fire_ts_df = (new_fire_df\n",
    " .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\"))\n",
    " .drop(\"CallDate\")\n",
    " .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\"))\n",
    " .drop(\"WatchDate\")\n",
    " .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"),\n",
    " \"MM/dd/yyyy hh:mm:ss a\"))\n",
    " .drop(\"AvailableDtTm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55552bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\")\n",
    " .show(5, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3abb21bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(year('IncidentDate'))\n",
    " .distinct()\n",
    " .orderBy(year('IncidentDate'))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49284bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(\"CallType\")\n",
    " .where(col(\"CallType\").isNotNull())\n",
    " .groupBy(\"CallType\")\n",
    " .count()\n",
    " .orderBy(\"count\", ascending=False)\n",
    " .show(n=10, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d6c234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|        176170|         3.892364154521585|               0.016666668|                   1844.55|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(fire_ts_df\n",
    " .select(F.sum(\"NumAlarms\"), F.avg(\"ResponseDelayedinMins\"),\n",
    " F.min(\"ResponseDelayedinMins\"), F.max(\"ResponseDelayedinMins\"))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc1ca1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|CallType                     |\n",
      "+-----------------------------+\n",
      "|Elevator / Escalator Rescue  |\n",
      "|Alarms                       |\n",
      "|Odor (Strange / Unknown)     |\n",
      "|Citizen Assist / Service Call|\n",
      "|HazMat                       |\n",
      "|Explosion                    |\n",
      "|Vehicle Fire                 |\n",
      "|Suspicious Package           |\n",
      "|Other                        |\n",
      "|Outside Fire                 |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What were all the different types of fire calls in 2018?\n",
    "(fire_ts_df\n",
    " .select(\"CallType\")\n",
    " .where(col(\"CallType\").isNotNull())\n",
    " .where(year('IncidentDate') == 2018)\n",
    " .distinct()\n",
    " .show(10, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760d099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|month(IncidentDate)|count|\n",
      "+-------------------+-----+\n",
      "|                 10| 1068|\n",
      "|                  5| 1047|\n",
      "|                  3| 1029|\n",
      "|                  8| 1021|\n",
      "|                  1| 1007|\n",
      "|                  6|  974|\n",
      "|                  7|  974|\n",
      "|                  9|  951|\n",
      "|                  4|  947|\n",
      "|                  2|  919|\n",
      "|                 11|  199|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What months within the year 2018 saw the highest number of fire calls?\n",
    "\n",
    "(fire_ts_df\n",
    " .filter(year(\"IncidentDate\") == 2018)\n",
    " .groupBy(month(\"IncidentDate\")).count()\n",
    " .orderBy(\"count\", ascending=False).show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39cdb200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        Neighborhood|count|\n",
      "+--------------------+-----+\n",
      "|          Tenderloin| 1393|\n",
      "|     South of Market| 1053|\n",
      "|             Mission|  913|\n",
      "|Financial Distric...|  772|\n",
      "|Bayview Hunters P...|  522|\n",
      "|    Western Addition|  352|\n",
      "|     Sunset/Parkside|  346|\n",
      "|            Nob Hill|  295|\n",
      "|        Hayes Valley|  291|\n",
      "|      Outer Richmond|  262|\n",
      "| Castro/Upper Market|  251|\n",
      "|         North Beach|  231|\n",
      "|           Excelsior|  212|\n",
      "|        Potrero Hill|  210|\n",
      "|  West of Twin Peaks|  210|\n",
      "|     Pacific Heights|  191|\n",
      "|              Marina|  191|\n",
      "|           Chinatown|  191|\n",
      "|         Mission Bay|  178|\n",
      "|      Bernal Heights|  170|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which neighborhood in San Francisco generated the most fire calls in 2018?\n",
    "\n",
    "(fire_ts_df\n",
    " .filter(year(\"IncidentDate\") == 2018)\n",
    " .groupBy(col(\"Neighborhood\")).count()\n",
    " .orderBy(\"count\", ascending=False)\n",
    " .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "853c07d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|        Neighborhood|ResponseDelayedinMins|\n",
      "+--------------------+---------------------+\n",
      "|           Chinatown|            491.26666|\n",
      "|Financial Distric...|            406.63333|\n",
      "|          Tenderloin|            340.48334|\n",
      "|      Haight Ashbury|            175.86667|\n",
      "|Bayview Hunters P...|                155.8|\n",
      "|Financial Distric...|            135.51666|\n",
      "|     Pacific Heights|            129.01666|\n",
      "|        Potrero Hill|                109.8|\n",
      "|        Inner Sunset|            106.13333|\n",
      "|     South of Market|             94.71667|\n",
      "+--------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which neighborhoods had the worst response times to fire calls in 2018?\n",
    "\n",
    "(fire_ts_df\n",
    " .filter(year(\"IncidentDate\") == 2018)\n",
    " .select(col(\"Neighborhood\"), col(\"ResponseDelayedinMins\"))\n",
    " .orderBy(\"ResponseDelayedinMins\", ascending=False)\n",
    " .show(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ae4446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|weekofyear(IncidentDate)|count|\n",
      "+------------------------+-----+\n",
      "|                      22|  259|\n",
      "|                      40|  255|\n",
      "|                      43|  250|\n",
      "|                      25|  249|\n",
      "|                       1|  246|\n",
      "+------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which week in the year in 2018 had the most fire calls?\n",
    "\n",
    "(fire_ts_df\n",
    " .filter(year(\"IncidentDate\") == 2018)\n",
    " .groupBy(weekofyear(\"IncidentDate\")).count()\n",
    " .orderBy(\"count\", ascending=False)\n",
    " .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae49ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+\n",
      "|        Neighborhood|zipcode|count|\n",
      "+--------------------+-------+-----+\n",
      "|          Tenderloin|  94102|17084|\n",
      "|     South of Market|  94103|13762|\n",
      "|             Mission|  94110|10444|\n",
      "|Bayview Hunters P...|  94124| 9150|\n",
      "|             Mission|  94103| 5445|\n",
      "+--------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Is there a correlation between neighborhood, zip code, and number of fire calls?\n",
    "\n",
    "(fire_ts_df\n",
    " .groupBy(col(\"Neighborhood\"), col(\"zipcode\")).count()\n",
    " .orderBy(\"count\", ascending=False)\n",
    " .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b6f9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can we use Parquet files or SQL tables to store this data and read it back?\n",
    "\n",
    "fire_ts_df.write.format(\"parquet\").saveAsTable(\"FireCalls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc2e99",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df95598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning Spark 2E'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row is a generic object type in Spark, holding a collection of mixed types that can be accessed using an index. \n",
    "\n",
    "from pyspark.sql import Row\n",
    "row = Row(350, True, \"Learning Spark 2E\", None)\n",
    "\n",
    "row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033b7e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236fd4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning Spark 2E'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94901fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
